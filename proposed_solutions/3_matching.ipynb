{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Matching profiles and offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif: Trouver les profils d'employées qui correspondent le mieux à chaque offre\n",
    "\n",
    "Exercices:\n",
    "\n",
    "1. Pour chaque offre, trouver l'employé pour lequel les compétences techniques et les compétences longues correspondent le mieux.\n",
    "\n",
    "Note: Les fonctions `offer_to_word_doc` et `profile_to_word_doc` dans `utils.py` aident à formatter un profil ou une offre en document Word pour aider à les visualiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/philippe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from flashtext import KeywordProcessor\n",
    "from nltk import stem\n",
    "from os.path import join\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "from unidecode import unidecode\n",
    "from utils import offer_to_word_doc, profile_to_word_doc\n",
    "\n",
    "tqdm.pandas()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "## Load and clean data\n",
    "We load all profile data: tech skills and experience descriptions are used to compute similarities, and profile job titles are used to check matching quality. We also load 10 offers for which we want to find the perfect profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_profiles = pd.read_csv('employee_profiles.csv')\n",
    "df_skills = pd.read_csv('employee_skills.csv')\n",
    "df_experiences = pd.read_csv('employee_experiences.csv')\n",
    "df_offers = pd.read_csv('offers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove profiles with too few skills\n",
    "n_min_tech_skill = 10\n",
    "mask_keep_profiles = df_skills.groupby(by=\"id_profile\", sort=False).count() > n_min_tech_skill\n",
    "selected_profile_ids = mask_keep_profiles[mask_keep_profiles.values].index\n",
    "df_profiles = df_profiles[df_profiles['id_profile'].isin(selected_profile_ids)]\n",
    "df_skills = df_skills[df_skills['id_profile'].isin(selected_profile_ids)]\n",
    "df_experiences = df_experiences[df_experiences['id_profile'].isin(selected_profile_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Subsample data: only work with 3000 profiles to speed things up\n",
    "# n_sub_sample = 3000\n",
    "# df_profiles = df_profiles.iloc[:n_sub_sample]\n",
    "# selected_profile_ids = set(df_profiles['id_profile'])\n",
    "# df_skills = df_skills[df_skills['id_profile'].isin(selected_profile_ids)]\n",
    "# df_experiences = df_experiences[df_experiences['id_profile'].isin(selected_profile_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Text cleaning function\n",
    "These functions were taken from the two previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_tech_skills(text: str) -> str:\n",
    "    \"\"\"Prepares text for keywords extractions.\"\"\"\n",
    "    punctuation = [\"!\", \"$\", \"%\", \",\", \":\", \";\", \"?\", \"[\", \"]\", \"|\"]\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, ' ' + p + ' ')\n",
    "    to_clean = text.strip()\n",
    "    to_clean = to_clean.replace('\\n', ' ')  # when job_title finishes in next line\n",
    "    to_clean = re.sub('\\s+', ' ', to_clean)  # replacing all spaces characters by one\n",
    "    to_clean = to_clean.replace(',', ' , ')\n",
    "\n",
    "    # Case where there is '.' in text:\n",
    "    if '.' in to_clean:\n",
    "        if re.findall(r'\\D[0-9]+\\.[\\S]', to_clean) != []:  # cas avec des versions de framework dans les keywords\n",
    "            to_clean = re.sub(r'\\D[0-9]+\\.[\\S]', '', to_clean)\n",
    "        if ' . ' in to_clean:\n",
    "            to_clean = to_clean.replace(' . ', '')\n",
    "        elif to_clean.endswith('.'):\n",
    "            to_clean = to_clean[:-1]\n",
    "\n",
    "    # Case where there is '-' in text\n",
    "    if '-' in to_clean:\n",
    "        if re.findall('\\w+-\\w+', to_clean) != []:\n",
    "            compound_words = re.findall('\\w{4,}-\\w{4,}', to_clean)\n",
    "            for cw in compound_words:\n",
    "                # Avoid cleaning tech words like ('e-commerce', '')\n",
    "                to_clean = to_clean.replace(cw, cw.replace('-', ' '))\n",
    "        else:\n",
    "            to_clean = to_clean.replace('-', ' ')\n",
    "\n",
    "    # Plus/hashtag sign cleaned only if it's surrounded by spaces\n",
    "    to_clean = to_clean.replace(' + ', ' ').replace(' # ', ' ').replace('_', ' ')\n",
    "\n",
    "    # Replacing apostrophe '’' by '''\n",
    "    to_clean = re.sub(\" *' *\", \"'\", to_clean.replace('’', \"'\"))\n",
    "\n",
    "    # Replacing articles with apostrophes\n",
    "    to_clean = re.sub(\"d'\", \"\", to_clean)\n",
    "    to_clean = re.sub(\"l'\", \"\", to_clean)\n",
    "\n",
    "    # Replacing /() by spaces\n",
    "    to_clean = to_clean.replace('/', ' ').replace('(', ' ').replace(')', ' ').replace('* ', '')\n",
    "    to_clean = to_clean.replace('- ', '').replace(':', '')\n",
    "\n",
    "    # Case where there is '&' in text\n",
    "    to_clean = to_clean.replace(' & ', ' et ')\n",
    "\n",
    "    # cleaning isolated numbers\n",
    "    to_clean = re.sub(' [0-9] ', '', to_clean)\n",
    "\n",
    "    cleaned = re.sub('\\s+', ' ', to_clean.strip())\n",
    "\n",
    "    return cleaned.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = stem.snowball.FrenchStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('french')\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    \"\"\"Returns a text with removed stopwords.\"\"\"\n",
    "    tt = []\n",
    "    for word in text.split(' '):\n",
    "        if word not in stopwords:\n",
    "            tt.append(word)\n",
    "    return \" \".join(tt).strip()\n",
    "\n",
    "\n",
    "def stem_sentence(text: str) -> str:\n",
    "    try:\n",
    "        text = ' '.join([stemmer.stem(word) for word in remove_stopwords(text.lower()).split(' ')])\n",
    "        text = unidecode(text)\n",
    "    except (TypeError, AttributeError):\n",
    "        return \"\"\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Setup TF-IDF to compute long skill similarities\n",
    "We will use TF-IDF to compute similarities between experience descriptions (aka. long skills) from profiles and offers. First we fit the TF-IDF using all profile experience descriptions. We then precompute TF-IDF vectors for all profiles so that we don't have to do it for each offer. The result is stored as a sparse CSR matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f773afafcb9645b4bd268df568811cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess long skills\n",
    "df_experiences['stemmed_description'] = df_experiences['description'].progress_apply(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit TF-IDF on stemmed experience descriptions\n",
    "tfidf_long_skill = TfidfVectorizer()\n",
    "tfidf_long_skill.fit(df_experiences['stemmed_description'].unique())\n",
    "\n",
    "# Pre-compute all profile long skill tf idf vectors\n",
    "experiences_tf_idf = tfidf_long_skill.transform(df_experiences['stemmed_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Setup TF-IDF to compute tech skill similarities\n",
    "For simplicity and speed, we will also use TF-IDF to compute similarities between tech skills from profiles and offers. First we fit the TF-IDF using all profile tech skills. We then precompute TF-IDF vectors for all profiles so that we don't have to do it for each offer. The result is stored as a sparse CSR matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess tech skills\n",
    "df_skills['skill'] = df_skills['skill'].apply(clean_tech_skills)\n",
    "df_offers['clean_description_for_skill'] = df_offers['description'].apply(clean_tech_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for computing similarities\n",
    "profiles_skills_df = df_skills.groupby(by='id_profile')['skill'].apply(lambda x: \" \".join(x)).reset_index()\n",
    "\n",
    "# Fit TF-IDF on profile tech skills and pre-compute all profile tech skill tf idf vectors\n",
    "tfidf_tech_skill = TfidfVectorizer()\n",
    "tech_skills_tf_idf = tfidf_tech_skill.fit_transform(profiles_skills_df[\"skill\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also prepare a keyword extractor to extract tech skills from offers. It will extract any tech skill found in cleaned profile tech skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tech skill extractor\n",
    "tech_skill_finder = KeywordProcessor()\n",
    "tech_skill_finder.add_keywords_from_list(list(set(df_skills['skill'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Functions to compute similarity between profiles and offers\n",
    "The two following functions take an offer description (or processed description) as an input as well as a sparse TF-IDF matrix for all profiles. It computes tech/long skill cosine similarity scores between TF-IDF vectors of all profiles and that of the offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_tech_skill_scores(profiles_skills_df: pd.DataFrame, tech_skills_tf_idf: csr_matrix,\n",
    "                          offer_clean_description: str) -> pd.DataFrame:\n",
    "    # Find tech keywords in offer description and convert to tf-idf vector\n",
    "    tech_skills = tech_skill_finder.extract_keywords(offer_clean_description)\n",
    "    offer_tf_idf = tfidf_tech_skill.transform([\" \".join(tech_skills)])\n",
    "\n",
    "    # Compute cosine similarity to all profile tech skill lists\n",
    "    skill_scores = cosine_similarity(tech_skills_tf_idf, offer_tf_idf).reshape(-1)\n",
    "\n",
    "    # Group experiences back with their profiles, and sum scores\n",
    "    profile_scores = pd.DataFrame({\"id_profile\": profiles_skills_df[\"id_profile\"], \"tech_score\": skill_scores})\n",
    "\n",
    "    return profile_scores.set_index(\"id_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_skill_scores(df_experiences: pd.DataFrame, experiences_tf_idf: csr_matrix,\n",
    "                          offer_description: str):\n",
    "    # Stem offer description and convert to tf-idf vector\n",
    "    stemmed_description = stem_sentence(offer_description)\n",
    "    offer_tf_idf = tfidf_long_skill.transform([stemmed_description])\n",
    "\n",
    "    # Compute cosine similarity to all experiences\n",
    "    experience_scores = cosine_similarity(experiences_tf_idf, offer_tf_idf).reshape(-1)\n",
    "\n",
    "    # Group experiences back with their profiles, and sum scores\n",
    "    experience_scores_df = pd.DataFrame({\"id_profile\": df_experiences[\"id_profile\"], \"long_score\": experience_scores})\n",
    "    profile_scores = experience_scores_df.groupby(\"id_profile\", sort=False).median()\n",
    "\n",
    "    return profile_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Matching 10 offers against all employees\n",
    "Looping through each offer, we compute tech skill and long skill similarity scores to all profiles. We sum the scores and output the profile that best matches the offer.\n",
    "Results are displayed below for all 10 offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippe/.anaconda3/envs/mobilite/lib/python3.8/site-packages/docx/styles/styles.py:139: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
      "  return self._get_style_id_from_style(self[style_name], style_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching results for offer 0 (developpeur logiciel):\n",
      " \tCandidate #286255\n",
      "\tScore: 0.342 (tech_score=0.233, mission_score=0.109)\n",
      "\tJob title: responsable de projet\n",
      "\tSkills: project management, agile methodologies, software project management, scrum, public transport, software development, agile project management, change management, information technology, software engineering, software design, software quality assurance, itil, business, informatics, java, c#, sql, php, .net, mysql, javascript, c++ language, oracle, embedded software, html, management, leadership, communication, développement de logiciel, méthodes agiles, gestion de projet, gestion de projet logiciel, intégration, déploiement de logiciel, intégration de données, recherche et développement, gestion équipe, sens de organisation, interoperability, billettique, mvc architecture, gmao, intégration logicielle, méthodologie, gestion des risques, direction\n",
      "\tExperiences: Responsable de développement et d'intégration - Chef de projet logiciel, Chef de projet GMAO, Ingénieur d'études en billettique, Ingénieur d'études en billettique, Ingénieur de recherche, Chargé de projet informatique, Développeur C / Unix\n",
      "\n",
      "\n",
      "Matching results for offer 1 (developpeur logiciel embarque c#):\n",
      " \tCandidate #691560\n",
      "\tScore: 0.273 (tech_score=0.214, mission_score=0.059)\n",
      "\tJob title: analyste de risques\n",
      "\tSkills: développement de logiciel, gestion de projet, analyse des besoins, testing, scrum, marketing, javascript, java, css3, mongodb, sql, nosql, php, r, python, android, node.js, github, git, uml, html, jquery, json, react, react native, trello, management, leadership, développement ios, gestion de projet agile, programmation web, management de programmes, méthodes agiles, analyse des exigences, analyse de données, méthodologies agile et waterfall, applications mobiles, conception de produit, lancement de produit, gestion des budgets, analyse commerciale, leadership équipe, service client, j2ee web services, haskell, product owner, analyse des besoins technologiques, développement applications agiles, gestion de programmes et de projets informatiques, gestion de projet logiciel\n",
      "\tExperiences: Product Manager, Product Owner, Product Owner, Chef de projet, Product Owner/Product Manager, Ingénieur en recherche et développement mobile, Développeur Full Stack, Développeur Android\n",
      "\n",
      "\n",
      "Matching results for offer 2 (chef de projet informatique):\n",
      " \tCandidate #691560\n",
      "\tScore: 0.354 (tech_score=0.269, mission_score=0.085)\n",
      "\tJob title: analyste de risques\n",
      "\tSkills: développement de logiciel, gestion de projet, analyse des besoins, testing, scrum, marketing, javascript, java, css3, mongodb, sql, nosql, php, r, python, android, node.js, github, git, uml, html, jquery, json, react, react native, trello, management, leadership, développement ios, gestion de projet agile, programmation web, management de programmes, méthodes agiles, analyse des exigences, analyse de données, méthodologies agile et waterfall, applications mobiles, conception de produit, lancement de produit, gestion des budgets, analyse commerciale, leadership équipe, service client, j2ee web services, haskell, product owner, analyse des besoins technologiques, développement applications agiles, gestion de programmes et de projets informatiques, gestion de projet logiciel\n",
      "\tExperiences: Product Manager, Product Owner, Product Owner, Chef de projet, Product Owner/Product Manager, Ingénieur en recherche et développement mobile, Développeur Full Stack, Développeur Android\n",
      "\n",
      "\n",
      "Matching results for offer 3 (chef de projet it):\n",
      " \tCandidate #819167\n",
      "\tScore: 0.294 (tech_score=0.199, mission_score=0.095)\n",
      "\tJob title: responsable de projet\n",
      "\tSkills: management, change management, consulting, management consulting, sourcing, coaching, consulting en management, recrutement it, stratégie, stratégie commerciale, ressources humaines, recrutement des diplômés, gestion de projet, recherche de dirigeants, coaching intégration, entretiens, système de suivi des candidatures, sélection, gestion des talents, amélioration des processus commerciaux, gestion du changement, marque employeur, sélection cv, systèmes information des ressources humaines hris, recrutement technique, recrutement cdd, recrutement universitaire\n",
      "\tExperiences: Cyber Evangelist, Responsable Recrutement et Marque Employeur, Talent Acquisition Manager\n",
      "\n",
      "\n",
      "Matching results for offer 4 (developpeur web):\n",
      " \tCandidate #385550\n",
      "\tScore: 0.304 (tech_score=0.292, mission_score=0.013)\n",
      "\tJob title: analyste de risques\n",
      "\tSkills: administration, sens de organisation, espagnol, microsoft office, microsoft excel, microsoft word, microsoft powerpoint, esprit analyse, adaptabilité, bon relationnel, gestion du temps, français, ecoute, polyvalence, esprit équipe, traiter information collecter , classer et mettre à jour\n",
      "\tExperiences: Conseillère relation client, Professeur d'espagnol, Assistante méthode, Tutrice pédagogique en français et d'accueil, Hôtesse de caisse et d'accueil, Stagiaire - Vendeuse comptoir, Hôtesse\n",
      "\n",
      "\n",
      "Matching results for offer 5 (developpeur web senior):\n",
      " \tCandidate #816090\n",
      "\tScore: 0.250 (tech_score=0.243, mission_score=0.008)\n",
      "\tJob title: développeur\n",
      "\tSkills: web, web design, développeur web, applications web, html, feuilles de style en cascade css, php, mysql, jquery, html5, ajax, javascript, git, sql, vue.js, react native, développement applications web\n",
      "\tExperiences: Développeur Web & Mobile\n",
      "\n",
      "\n",
      "Matching results for offer 6 (Analyste Senior Risque Pays):\n",
      " \tCandidate #517292\n",
      "\tScore: 0.382 (tech_score=0.365, mission_score=0.017)\n",
      "\tJob title: analyste de risques\n",
      "\tSkills: management, relations internationales, sécurité internationale, gouvernance européenne, pratiques diplomatiques contemporaines, gestion des risques et des crises, géopolitique, intelligence économique, gestion des risques, diplomatie, stratégie, analyse, synthèse, conseil, veille stratégique, fiches pays, risque pays, géostratégie, défense, sécurité, gestion de crise, environnement international, commerce international\n",
      "\tExperiences: Risk Management Officer - Geopolitical Analyst, Volunteering - Organisation and promotion China International Import Expo CIIE, Communication Officer, Public Affairs, Ambassador, Public Affairs, Research Analyst - Defense & Security - CSFRS, Mission Delegate, Auditor, Risk Management\n",
      "\n",
      "\n",
      "Matching results for offer 7 (ANALYSTE RISQUES IT & CYBERSECURITÉ H/F):\n",
      " \tCandidate #208892\n",
      "\tScore: 0.478 (tech_score=0.448, mission_score=0.030)\n",
      "\tJob title: analyste de risques\n",
      "\tSkills: change management, project coordination, finance, gestion de projet, banque, banking, it management, informatique décisionnelle, project management, software project management, gestion de projet logiciel, stratégie it, gestion des risques, crm, marché financier, risk management, business intelligence, it operations, management it, it solutions, analyste commercial\n",
      "\tExperiences: Responsable de la Cohérence du SI et de l'Innovation, Directeur-adjoint du SI du Financement Local, Responsable de service Etudes SI Prêts, Infocentre & Décisionnel, Responsable de service Etudes SI Service Client, Responsable de pôle, Chef de projet\n",
      "\n",
      "\n",
      "Matching results for offer 8 (Ingénieur R&D Procédés / Hydrogène):\n",
      " \tCandidate #421928\n",
      "\tScore: 0.350 (tech_score=0.335, mission_score=0.015)\n",
      "\tJob title: ingénieur r&d\n",
      "\tSkills: r&d, recherche, gestion des essais, matlab, microsoft office, microsoft excel, microsoft word, énergie, énergie renouvelable, physique, traitement de image, turbulence, hydrogène\n",
      "\tExperiences: Ingénieur/Docteur R&D, Ingenieur Etude - R&D, Ingénieur R&D, Ingénieur essais, Ingénieur de recherche, Chercheur stagiaire sur les piles à combustible haute température / Researcher trainee on SOFC-SOEC, Chargé de mission énergétique\n",
      "\n",
      "\n",
      "Matching results for offer 9 (Ingénieur Développement (R&D)):\n",
      " \tCandidate #436483\n",
      "\tScore: 0.434 (tech_score=0.427, mission_score=0.007)\n",
      "\tJob title: analyste de risques\n",
      "\tSkills: technicien hydraulique urbaine, gestion de projet, traitement des eaux, alimentation en eau, humanitaire, distribution de eau, assistance technique, traitement des eaux usées, hydraulique, qualité de eau, contrôle conformité\n",
      "\tExperiences: Technicien, Technicien réseau\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_dir = \"matching\"\n",
    "for i, offer in df_offers.iterrows():\n",
    "    # Convert offers to Word document\n",
    "    offer_to_word_doc(*df_offers[[\"jobtitle\", \"description\", \"contract\", \"company\", \"location\"]].iloc[i],\n",
    "                      out_file_name=join(match_dir, f\"{i}_offre.docx\"))\n",
    "    \n",
    "    # Tech skill matching\n",
    "    tech_skill_scores = get_tech_skill_scores(profiles_skills_df, tech_skills_tf_idf,\n",
    "                                              offer[\"clean_description_for_skill\"])\n",
    "\n",
    "    # Long skill matching\n",
    "    long_skill_scores = get_long_skill_scores(df_experiences, experiences_tf_idf, offer[\"description\"])\n",
    "\n",
    "    # Combine scores\n",
    "    df_scores = pd.merge(tech_skill_scores, long_skill_scores, left_index=True, right_index=True, how=\"outer\")\n",
    "    df_scores = df_scores.fillna(0)  # In case a score is missing\n",
    "    df_scores[\"global_score\"] = df_scores.sum(axis=1)\n",
    "    best_profile_id = df_scores[\"global_score\"].idxmax().item()\n",
    "    global_score = df_scores.at[best_profile_id, \"global_score\"]\n",
    "    tech_skill_score = df_scores.at[best_profile_id, \"tech_score\"]\n",
    "    long_skill_score = df_scores.at[best_profile_id, \"long_score\"]\n",
    "    \n",
    "    # Convert best profile to Word document\n",
    "    profile_to_word_doc(best_profile_id, df_profiles, df_skills, df_experiences,\n",
    "                        out_file_name=join(match_dir, f\"{i}_candidate.docx\"))\n",
    "\n",
    "\n",
    "    # Best candidate\n",
    "    print(f\"\\nMatching results for offer {i} ({offer['jobtitle']}):\\n \"\n",
    "          f\"\\tCandidate #{best_profile_id}\\n\"\n",
    "          f\"\\tScore: {global_score:.3f} (tech_score={tech_skill_score:.3f}, mission_score={long_skill_score:.3f})\\n\"\n",
    "          f\"\\tJob title: {df_profiles.loc[df_profiles['id_profile'] == best_profile_id, 'jobtitle'].item()}\\n\"\n",
    "          f\"\\tSkills: {', '.join(df_skills.loc[df_skills['id_profile'] == best_profile_id, 'skill'])}\\n\"\n",
    "          f\"\\tExperiences: {', '.join(df_experiences.loc[df_experiences['id_profile'] == best_profile_id, 'title'])}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
